---
title: "LogicCat: Text-to-SQL Benchmark for Multi-Domain Reasoning Challenges"
collection: publications
category: manuscripts
permalink: /publication/2025-07-01-logiccat
excerpt: 'A comprehensive benchmark for evaluating Text-to-SQL systems on multi-domain reasoning challenges.'
date: 2025-07-01
venue: 'ArXiv Preprint'
paperurl: 'https://arxiv.org/abs/2505.18744'
citation: 'Tao Liu, **Xutao Mao**, Hongying Zan, Yifan Li, Dixuan Zhang, Lulu Kong, Haixin Liu, Jiaming Hou, Aoze Zheng, Rui Li, Yiming Qiao, Zewei Luo, Qi Wang, Zhiqiang Zhang, Jiaxi Li, Supeng Liu, Kunli Zhang, Min Peng (2025). &quot;LogicCat: Text-to-SQL Benchmark for Multi-Domain Reasoning Challenges.&quot; <i>ArXiv Preprint</i>.'
---
This paper introduces LogicCat, a comprehensive benchmark for evaluating Text-to-SQL systems on multi-domain reasoning challenges. The benchmark provides a standardized evaluation framework for complex SQL generation tasks, enabling systematic assessment of model performance across diverse reasoning scenarios. 